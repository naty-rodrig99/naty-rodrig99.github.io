<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Natalia Rodriguez</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- ====Favicons==== -->
    <!-- <link rel="shortcut icon" href="img/favicon.png" type="image/x-icon"> -->
    <link rel="icon" href="favicon.png" type="image/x-icon">
    
    <!-- ==== Google Font ==== -->
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">

    <!-- ==== Font Awesome ==== -->
    <link href="css/font-awesome.min.css" rel="stylesheet">
    
    <!-- ==== Bootstrap ==== -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    
    <!-- ==== jQuery UI ==== -->
    <link href="css/jquery-ui.min.css" rel="stylesheet">
    
    <!-- ==== Owl Carousel Plugin ==== -->
    <link href="css/owl.carousel.min.css" rel="stylesheet">
    
    <!-- ====Main Stylesheet==== -->
    <link href="style.css" rel="stylesheet">
    
    <!-- ====Custom Stylesheet==== -->
    <link href="css/custom-style.css" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-157444923-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-157444923-1');
    </script>

    <style>
        #myCarousel li{
            background-color: rgba(0,0,0,.2);
            border: initial;
        }

        #myCarousel li.active{
            background-color: #666;
        }

        #myCarousel ol {
            bottom: -50px; letter-spacing: 3px; z-index: 0;
        }

    </style>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="js/html5shiv.min.js"></script>
        <script src="js/respond.min.js"></script>
    <![endif]-->
</head>
<body data-spy="scroll" data-target=".navbar" data-offset="100">
    <!-- Wrapper Start -->
    <div class="wrapper">


        <!-- Side Nav Start -->
                        <div class="side" id="side">
                            <ul>
                                <li><a href="#ai1">Overview</a></li>
                                <li><a href="#ai2">Research Process</a></li>
                                <li><a href="#ai3">Results</a></li>
                                <li><a href="#ai4">Discussion</a></li>
                                <li><a href="#ai5">Relflection</a></li>
                            <!--<li><a href="#RM">Remarks</a></li>-->
                            </ul>
                        </div>
        <!-- Side Nav End -->
        
        <!-- Header Area Start -->
        <div id="header">
            <nav class="header--navbar">
                <div class="container">
                    <div class="navbar">
                        <div class="navbar-header">
                        
                            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#headerNav" aria-expanded="false" aria-controls="headerNav">
                                <span class="sr-only">Toggle navigation</span>
                                <span class="icon-bar"></span>
                                <span class="icon-bar"></span>
                                <span class="icon-bar"></span>
                            </button>
                            
                            <!-- Logo Start -->
                            <a class="logo navbar-brand" href="index.html">
                                
                                <div class="logo--content" id="logo--content">
                                    <h1>Natalia Rodriguez</h1>
                                    <p>Portfolio</p>
                                </div>
                            </a>
                            <!-- Logo End -->
                        </div>
                       
                        <div id="headerNav" class="header--nav navbar-collapse collapse">
                            <ul class="nav navbar-nav navbar-right AnimateScroll">
                                <li><a href="https://naty-rodrig99.github.io//#header">HOME</a></li>
                                <li><a href="https://naty-rodrig99.github.io//#gallery">PROJECTS</a></li>
                                <li><a href="https://naty-rodrig99.github.io//#skills">SKILLS</a></li>
                                <li><a href="https://naty-rodrig99.github.io//#about">ABOUT</a></li>
                                <!--<li><a href="/pdf/peiyunchung_cv.pdf" target="_blank">RESUME</a></li> -->          
                                <li><a href="https://www.linkedin.com/in/natalia-ra04/">LINKEDIN</a></li>
                            </ul>
                        </div>
                        <!-- Header Nav End -->
                    </div>
                </div>
            </nav>
        </div>
        <!-- Header Area End -->

            <!-- Body Area Start -->
            <div class="container">

                <!-- Modal Body Start -->
                <div class="modal-body">
                    <div class="row">
                        <div class="col-md-offset-1 col-md-10 col-xs-offset-1 col-xs-10 reset-padding post-title">
                            <h2 id="ai1">Research on Trust, Gender, and Social Perception in Human-Robot Interactions</h2>
                            <h4>Master's Thesis Project</h4>
                        </div>

                        <div class="col-md-12" style="text-align: center;" id="ai1">
                            <img src="img/project-img/hri-main.png" alt="" class="img-responsive" style="width: 35%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        
                        <div class="col-md-offset-1 col-md-10 col-xs-offset-1 col-xs-10 reset-padding post-content">

                    <div class="row">
                        <div class="col-md-8">

                            <h5>OVERVIEW</h5>
                            <p>As artificial intelligence and social robots become more common in daily life, their success depends not only on technical performance but also on how humans perceive and interact with them. People naturally anthropomorphize robots, projecting traits and social expectations, especially when robots have cues like voice, facial expressions, or body language. These design choices, particularly related to gender, influence perceptions of trust, competence, and role suitability. Feminist robot studies have highlighted how gendered designs can reinforce harmful stereotypes, promoting calls for more inclusive and ethically responsible design approaches. </p>


                            <h5>OBJECTIVE</h5>
                            <p>While previous research has focused on male and female robot personas, little is known about how users respond to gender-ambiguous robots. This study explores how trust and perception are shaped by a gender-ambiguous robot's performance and task context, considering user characteristics like age and previous experience with robots. By doing so, it challenges traditional gender norms in robot design and advocates for more socially aware and inclusive human-robot interaction practices.</p>
                            
                            <h5>PROBLEM STATEMENT</h5>
                            <p style="text-align: center"><strong>"How do user interactions with a gender-ambiguous social robot vary with task performance and task context?"</strong></p>

                        </div>

                        <div class="col-md-1"></div>                     
                          
                        <div class="col-md-3">
                            <h5>ITEM</h5>
                            <p>Master's Thesis Project</p> 

                            <h5>METHODS</h5>
                            <p>Survey, Quantitative Research, Statistical Analysis</p>

                            <h5>TOOLS</h5>
                            <p>Furhat Robot, Python, Amazon Mechanical Turk, Kotlin</p>  
                            
                            <h5>PRESENTATION</h5>
                            <u><a href="https://github.com/naty-rodrig99/sentiment_classification">Slides</a></u>

                            <h5>TEAM</h5>
                            <p>Individual</p>
                            
                            <h5>PERIOD</h5>
                            <p>February 2025 - August 2025</p> 
                        </div>
                    </div>

                <div class="divider" id="ai2">
                    <div class="dot1"></div>
                    <div class="dot2"></div>
                    <div class="dot3"></div>
                </div>  
                    
                    <h3>Background</h3>

                    

                    <div class="divider" id="ai2">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  

                    <h3>METHODOLOGY</h3>
                    <p>The experiment involves defining two different contexts that have been determined to be stereotypically more associated with a role that a male would perform, and another role that is more associated with a task a female would do. Then, recording videos of different users interacting with the robot, in half of the videos the robot will perform without failures, and in the other half with failures. Followed by creating a survey and recruiting participants to watch and rate the different interactions. Lastly, a statistical analysis will be performed to come up with conclusions.</p>

                    <br>

                    <h4>Experiment Design</h4>

                    <div class="row">
                        <div class="col-md-7">
                            <h5>Robot Selection</h5>
                            <p><bold>Furhat robot</bold> was chosen for this experiment, since it allows to <bold>customize</bold> the <bold>face and voice</bold>, enabling the creation of an <bold>intentionally ambiguous</bold> appearance, as well as its established use in prior social robotics research.</p>  
                            <ul>
                                <li>Face: Ted</li>
                                <li>Voice: Amazon Polly’s “Kendra” voice with a lowered pitch</li>
                            </ul>
                        </div>
                        
                        <div class="col-md-5">
                            <img src="img/project-img/hri-furhat.jpeg" alt="" class="img-responsive" style="width: 30%; height: auto;  margin: 0; display: block;">
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-md-6">
                            <img src="img/project-img/hri-contexts.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0; display: block;">
                        </div>
                        
                        <div class="col-md-6">
                            <h5>Context Design</h5>
                            <p>To examine how task stereotypes influence perceptions of a gender-ambiguous robot, two contexts were selected based on common gender associations in past research:</p>  
                            <ul>
                                <li>Assistant: perceived as a female task, due to its frequent use in voice assistant design and associations with caregiving and support.</li>

                                <li>IT Support: perceived as a male task, due to its commonly societal associations with technology and robots.</li>
                            </ul>
                        </div>  
                    </div>

                    <div class="row">
                        <div class="col-md-6">
                            <h5>Robot Behavior & Video Setup</h5>
                            <p>For each context, Furhat was programmed to behave in 2 ways:</p>  
                            <ul>
                                <li>Robot functioning with <strong>technical</strong> (speaking slowly and crashing) and <strong>interaction</strong> (providing the user nonsensical responses) <bold>failures</bold>.</li>
                                <li>Robot functioning <strong>without any failures</strong> while responding to the user.</li>
                            </ul>
                        </div>
                        
                        <div class="col-md-6">
                            <h5>Video Example</h5>
                            <iframe width="360" height="215" src="https://www.youtube.com/embed/jYem_HGhyrI?si=SPeOk3yCFpwpC3Ox" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                        </div>
                    </div>

                    <h4>Survey Design</h4>
                    <ul>
                        <li>A survey was used to enable statistical analysis, apply validated scales (e.g., trust, social perception), and ensure comparability with prior HRI studies.</li>
                        <li>Built on Amazon Mechanical Turk with custom HTML/CSS, participants were randomly shown either 4 failure or 4 no-failure videos. </li>
                        <li>After giving consent and sharing demographics, participants rated trust, social perception, and the robot’s perceived gender after each video.</li>
                    </ul>
                    
                    <img src="img/project-img/hri-methodology.png" alt="" class="img-responsive" style="width: 90%; height: auto;  margin: 0 auto; display: block;">

                    <h4>Metrics</h4>
                    <p>The following metrics were used to measure trust, social perception, and the robot’s perceived gender. Each used a Likert scale, and the items within each scale were randomized to reduce order effects.</p>

                    <div class="row">
                        <div class="col-md-4">
                            <img src="img/project-img/hri-mdmt.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0; display: block;">
                        </div>                        
                        <div class="col-md-4">
                            <img src="img/project-img/hri-rosas.png" alt="" class="img-responsive" style="width: 90%; height: auto;  margin: 0; display: block;">
                        </div>
                        <div class="col-md-4">
                            <img src="img/project-img/hri-gender.png" alt="" class="img-responsive" style="width: 90%; height: auto;  margin: 0; display: block;">
                        </div>
                    </div>

                    <h4>Attention Checks</h4>
                    <p>To ensure participant attention, an open-ended question was included among the trait items <strong>asking participants to describe what the robot in the video is doing</strong>. Additionally, each video rating included a <strong>randomly placed, unrelated word (e.g. apple, zebra, broccoli, and banana)</strong> within the MDMT (Multi-Dimensional Measure of Trust) scale. Participants were expected to select “Does Not Fit” for these words, serving as an attention check.</p>

                    <br>
                    <h4>Participants</h4>
                    <div class="row">
                        <div class="col-md-6">
                            <p>Sample size was determined via simulation power analysis, assuming:</p>
                            <img src="img/project-img/hri-power.png" alt="" class="img-responsive" style="width: 50%; height: auto;  margin: 0; display: block;">
                        </div>
                        <div class="col-md-6">
                            <ul>
                                <li>Participants were recruited through Amazon Mechanical Turk.</li>
                                <li>Total of 210 participants: 105 in the no robot failures condition and 105 in the robot failures condition</li>
                                <li>Each participant had 45 minutes to complete the survey.</li>
                                <li>Age range: 20 to 69</li>
                            </ul>
                        </div>
                        <h5>Participants' Gender Identification:</h5>
                        <img src="img/project-img/hri-participants.png" alt="" class="img-responsive" style="width: 40%; height: auto;  margin: 0; display: block;">
                    </div>

                    <h4>Data Analysis</h4>

                    <img src="img/project-img/hri-data.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0; display: block;">

                    <div class="divider" id="ai2">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  

                    <h3>RESULTS</h3>
                    <p>These were the final results comparing both algorithms:</p>
                    <img src="img/project-img/sent-table.png" alt="" class="img-responsive" style="width: 60%; height: auto;  margin: 0 auto; display: block;">

                    <div class="divider" id="ai2">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  
                    
                    <h3>REFLECTION</h3>


                    <h4>Future Work</h4>

                    <ul>
                        <li><strong>Deep Learning Models: </strong>Exploring deep learning models like recurrent neural networks (RNNs) or transformers could offer even better performance on sentiment classification tasks involving large text datasets.</li>
                        <li><strong>Data Sources: </strong>Look for additional data sources or more diverse datasets to train and evaluate the models, improving generalization.</li>
                    </ul>



                    <h4>Persona Takeaways</h4>

                    <ul>
                        <li>Gained insights into the strengths and weaknesses of different classification algorithms (Naïve Bayes vs. SVM) and how their performance varies based on the dataset.</li>
                        <li>Became interested in exploring more advanced techniques and algorithms for text classification, recognizing the potential for improved performance.</li>
                    </ul>



                        </div>
                    </div>
                </div>
                <!-- Modal Body End -->

            </div>
            <!-- Body Area End -->      
         
  
        <!-- Footer Area Start -->
        <div id="footer">
            <!-- Contact Social Start -->
            <div class="contact--social">
                <ul>
                    <li><a title="LinkedIn" target="_blank" href="https://www.linkedin.com/in/natalia-ra04/"><i class="fa fa-linkedin"></i></a></li>
                    <li><a title="GitHib" target="_blank" href="https://github.com/naty-rodrig99"><i class="fa fa-github"></i></a></li>                   
                </ul>
            </div>
            <!-- Contact Social End -->            
            <div class="container">
                <!-- Footer Copyright Start -->
                <div class="footer--copyright" style="font-weight: 300; color: #999999;">
                    <p>Copyright &copy; 2025 <a href="index.html" style=" color: #999999;">Natalia Rodriguez</a>. All Rights Reserved.</p>
                </div>
                <!-- Footer Copyright End -->
            </div>
        </div>
        <!-- Footer Area End -->
        
        <!-- Back To Top Area Start -->
        <div id="backToTop">
            <a href="#header" class="btn--default AnimateScrollLink"><i class="fa fa-angle-up"></i></a>
        </div>
        <!-- Back To Top Area End -->
    </div>
    <!-- Wrapper End -->

    <!-- ==== jQuery ==== -->
    <script src="js/jquery.min.js"></script>

    <!-- ==== Bootstrap ==== -->
    <script src="js/bootstrap.min.js"></script>

    <!-- ==== jQuery UI DatePicker Plugin ==== -->
    <script src="js/jquery-ui.min.js"></script>

    <!-- ==== Owl Carousel Plugin ==== -->
    <script src="js/owl.carousel.min.js"></script>

    <!-- ==== Isotope Plugin ==== -->
    <script src="js/isotope-docs.min.js"></script>
    
    <!-- ==== jQuery Form Plugin ==== -->
    <script src="js/jquery.form.min.js"></script>
    
    <!-- ==== jQuery Validation Plugin ==== -->
    <script src="js/jquery.validate.min.js"></script>

    <!-- ==== Google Map API ==== -->
    <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBK9f7sXWmqQ1E-ufRXV3VpXOn_ifKsDuc"></script>
    
    <!-- ==== GMaps Plugin ==== -->
    <script src="js/gmaps.min.js"></script>
    
    <!-- ==== jQuery Waypoints Plugin ==== -->
    <script src="js/jquery.waypoints.min.js"></script>
    
    <!-- ==== Animate Scroll Plugin ==== -->
    <script src="js/animatescroll.min.js"></script>
    
    <!-- ==== CounterUp Plugin ==== -->
    <script src="js/jquery.counterup.min.js"></script>
    
    <!-- ==== jQuery Nice Scroll Plugin ==== -->
    <script src="js/jquery.nicescroll.min.js"></script>
    
    <!-- ==== Parallax Plugin ==== -->
    <script src="js/parallax.min.js"></script>
    
    <!-- ==== jQuery Tubular Plugin ==== -->
    <script src="js/jquery.tubular.1.0.js"></script>
    
    <!-- ==== RetinaJS Plugin ==== -->
    <script src="js/retina.min.js"></script>

    <!-- ==== Main Script ==== -->
    <script src="js/main.js"></script>

</body>
</html>

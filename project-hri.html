<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Natalia Rodriguez</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- ====Favicons==== -->
    <!-- <link rel="shortcut icon" href="img/favicon.png" type="image/x-icon"> -->
    <link rel="icon" href="favicon.png" type="image/x-icon">
    
    <!-- ==== Google Font ==== -->
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">

    <!-- ==== Font Awesome ==== -->
    <link href="css/font-awesome.min.css" rel="stylesheet">
    
    <!-- ==== Bootstrap ==== -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    
    <!-- ==== jQuery UI ==== -->
    <link href="css/jquery-ui.min.css" rel="stylesheet">
    
    <!-- ==== Owl Carousel Plugin ==== -->
    <link href="css/owl.carousel.min.css" rel="stylesheet">
    
    <!-- ====Main Stylesheet==== -->
    <link href="style.css" rel="stylesheet">
    
    <!-- ====Custom Stylesheet==== -->
    <link href="css/custom-style.css" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-157444923-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-157444923-1');
    </script>

    <style>
        #myCarousel li{
            background-color: rgba(0,0,0,.2);
            border: initial;
        }

        #myCarousel li.active{
            background-color: #666;
        }

        #myCarousel ol {
            bottom: -50px; letter-spacing: 3px; z-index: 0;
        }

    </style>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="js/html5shiv.min.js"></script>
        <script src="js/respond.min.js"></script>
    <![endif]-->
</head>
<body data-spy="scroll" data-target=".navbar" data-offset="100">
    <!-- Wrapper Start -->
    <div class="wrapper">


        <!-- Side Nav Start -->
                        <div class="side" id="side">
                            <ul>
                                <li><a href="#ai1">Overview</a></li>
                                <li><a href="#ai2">Research Process</a></li>
                                <li><a href="#ai3">Results</a></li>
                                <li><a href="#ai4">Discussion</a></li>
                                <li><a href="#ai5">Relflection</a></li>
                            <!--<li><a href="#RM">Remarks</a></li>-->
                            </ul>
                        </div>
        <!-- Side Nav End -->
        
        <!-- Header Area Start -->
        <div id="header">
            <nav class="header--navbar">
                <div class="container">
                    <div class="navbar">
                        <div class="navbar-header">
                        
                            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#headerNav" aria-expanded="false" aria-controls="headerNav">
                                <span class="sr-only">Toggle navigation</span>
                                <span class="icon-bar"></span>
                                <span class="icon-bar"></span>
                                <span class="icon-bar"></span>
                            </button>
                            
                            <!-- Logo Start -->
                            <a class="logo navbar-brand" href="index.html">
                                
                                <div class="logo--content" id="logo--content">
                                    <h1>Natalia Rodriguez</h1>
                                    <p>Portfolio</p>
                                </div>
                            </a>
                            <!-- Logo End -->
                        </div>
                       
                        <div id="headerNav" class="header--nav navbar-collapse collapse">
                            <ul class="nav navbar-nav navbar-right AnimateScroll">
                                <li><a href="https://naty-rodrig99.github.io//#header">HOME</a></li>
                                <li><a href="https://naty-rodrig99.github.io//#gallery">PROJECTS</a></li>
                                <li><a href="https://naty-rodrig99.github.io//#skills">SKILLS</a></li>
                                <li><a href="https://naty-rodrig99.github.io//#about">ABOUT</a></li>
                                <!--<li><a href="/pdf/peiyunchung_cv.pdf" target="_blank">RESUME</a></li> -->          
                                <li><a href="https://www.linkedin.com/in/natalia-ra04/">LINKEDIN</a></li>
                            </ul>
                        </div>
                        <!-- Header Nav End -->
                    </div>
                </div>
            </nav>
        </div>
        <!-- Header Area End -->

            <!-- Body Area Start -->
            <div class="container">

                <!-- Modal Body Start -->
                <div class="modal-body">
                    <div class="row">
                        <div class="col-md-offset-1 col-md-10 col-xs-offset-1 col-xs-10 reset-padding post-title">
                            <h2 id="ai1">Research on Trust, Gender, and Social Perception in Human-Robot Interactions</h2>
                            <h4>Master's Thesis Project</h4>
                        </div>

                        <div class="col-md-12" style="text-align: center;" id="ai1">
                            <img src="img/project-img/hri-main.png" alt="" class="img-responsive" style="width: 35%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        
                        <div class="col-md-offset-1 col-md-10 col-xs-offset-1 col-xs-10 reset-padding post-content">

                    <div class="row">
                        <div class="col-md-8">

                            <h5>OVERVIEW</h5>
                            <p>As artificial intelligence and social robots become more common in daily life, their success depends not only on technical performance but also on how humans perceive and interact with them. People naturally anthropomorphize robots, projecting traits and social expectations, especially when robots have cues like voice, facial expressions, or body language. These design choices, particularly related to gender, influence perceptions of trust, competence, and role suitability. Feminist robot studies have highlighted how gendered designs can reinforce harmful stereotypes, promoting calls for more inclusive and ethically responsible design approaches. </p>


                            <h5>OBJECTIVE</h5>
                            <p>While previous research has focused on male and female robot personas, little is known about how users respond to gender-ambiguous robots. This study explores how trust and perception are shaped by a gender-ambiguous robot's performance and task context, considering user characteristics like age and previous experience with robots. By doing so, it challenges traditional gender norms in robot design and advocates for more socially aware and inclusive human-robot interaction practices.</p>
                            
                            <h5>PROBLEM STATEMENT</h5>
                            <p style="text-align: center"><strong>"How do user interactions with a gender-ambiguous social robot vary with task performance and task context?"</strong></p>

                        </div>

                        <div class="col-md-1"></div>                     
                          
                        <div class="col-md-3">
                            <h5>ITEM</h5>
                            <p>Master's Thesis Project</p> 

                            <h5>METHODS</h5>
                            <p>Survey, Quantitative Research, Statistical Analysis</p>

                            <h5>TOOLS</h5>
                            <p>Furhat Robot, Python, Amazon Mechanical Turk, Kotlin</p>  
                            
                            <h5>PRESENTATION</h5>
                            <u><a href="https://github.com/naty-rodrig99/sentiment_classification">Slides</a></u>

                            <h5>TEAM</h5>
                            <p>Individual</p>
                            
                            <h5>PERIOD</h5>
                            <p>February 2025 - August 2025</p> 
                        </div>
                    </div>

                <div class="divider" id="ai2">
                    <div class="dot1"></div>
                    <div class="dot2"></div>
                    <div class="dot3"></div>
                </div>  
                    
                    <h3>Background</h3>

                    <h4>Hypotheses</h4>
                    <p>To structure the study, these hypotheses have been defined. These reflect the expectations about how failures, task context, and participant differences affect trust, gender perception, and social perception of the robot:</p>
                    <img src="img/project-img/hri-hypotheses.png" alt="" class="img-responsive" style="width: 50%; height: auto; margin: 0 auto; display: block;">
                    
                    <div class="divider" id="ai2">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  

                    <h3>METHODOLOGY</h3>
                    <p>The experiment involves defining two different contexts that have been determined to be stereotypically more associated with a role that a male would perform, and another role that is more associated with a task a female would do. Then, recording videos of different users interacting with the robot, in half of the videos the robot will perform without failures, and in the other half with failures. Followed by creating a survey and recruiting participants to watch and rate the different interactions. Lastly, a statistical analysis will be performed to come up with conclusions.</p>

                    <br>

                    <h4>Experiment Design</h4>

                    <div class="row">
                        <div class="col-md-7">
                            <h5>Robot Selection</h5>
                            <p><bold>Furhat robot</bold> was chosen for this experiment, since it allows to <bold>customize</bold> the <bold>face and voice</bold>, enabling the creation of an <bold>intentionally ambiguous</bold> appearance, as well as its established use in prior social robotics research.</p>  
                            <ul>
                                <li>Face: Ted</li>
                                <li>Voice: Amazon Polly’s “Kendra” voice with a lowered pitch</li>
                            </ul>
                        </div>
                        
                        <div class="col-md-5">
                            <img src="img/project-img/hri-furhat.jpeg" alt="" class="img-responsive" style="width: 30%; height: auto;  margin: 0; display: block;">
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-md-6">
                            <img src="img/project-img/hri-contexts.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0; display: block;">
                        </div>
                        
                        <div class="col-md-6">
                            <h5>Context Design</h5>
                            <p>To examine how task stereotypes influence perceptions of a gender-ambiguous robot, two contexts were selected based on common gender associations in past research:</p>  
                            <ul>
                                <li>Assistant: perceived as a female task, due to its frequent use in voice assistant design and associations with caregiving and support.</li>

                                <li>IT Support: perceived as a male task, due to its commonly societal associations with technology and robots.</li>
                            </ul>
                        </div>  
                    </div>

                    <div class="row">
                        <div class="col-md-6">
                            <h5>Robot Behavior & Video Setup</h5>
                            <p>For each context, Furhat was programmed to behave in 2 ways:</p>  
                            <ul>
                                <li>Robot functioning with <strong>technical</strong> (speaking slowly and crashing) and <strong>interaction</strong> (providing the user nonsensical responses) <bold>failures</bold>.</li>
                                <li>Robot functioning <strong>without any failures</strong> while responding to the user.</li>
                            </ul>
                        </div>
                        
                        <div class="col-md-6">
                            <h5>Video Example</h5>
                            <iframe width="360" height="215" src="https://www.youtube.com/embed/jYem_HGhyrI?si=SPeOk3yCFpwpC3Ox" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                        </div>
                    </div>

                    <h4>Survey Design</h4>
                    <ul>
                        <li>A survey was used to enable statistical analysis, apply validated scales (e.g., trust, social perception), and ensure comparability with prior HRI studies.</li>
                        <li>Built on Amazon Mechanical Turk with custom HTML/CSS, participants were randomly shown either 4 failure or 4 no-failure videos. </li>
                        <li>After giving consent and sharing demographics, participants rated trust, social perception, and the robot’s perceived gender after each video.</li>
                    </ul>
                    
                    <img src="img/project-img/hri-methodology.png" alt="" class="img-responsive" style="width: 90%; height: auto;  margin: 0 auto; display: block;">

                    <h4>Metrics</h4>
                    <p>The following metrics were used to measure trust, social perception, and the robot’s perceived gender. Each used a Likert scale, and the items within each scale were randomized to reduce order effects.</p>

                    <div class="row">
                        <div class="col-md-4">
                            <img src="img/project-img/hri-mdmt.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0; display: block;">
                        </div>                        
                        <div class="col-md-4">
                            <img src="img/project-img/hri-rosas.png" alt="" class="img-responsive" style="width: 80%; height: auto;  margin: 0; display: block;">
                        </div>
                        <div class="col-md-4">
                            <img src="img/project-img/hri-gender.png" alt="" class="img-responsive" style="width: 90%; height: auto;  margin: 0; display: block;">
                        </div>
                    </div>

                    <h4>Attention Checks</h4>
                    <p>To ensure participant attention, an open-ended question was included among the trait items <strong>asking participants to describe what the robot in the video is doing</strong>. Additionally, each video rating included a <strong>randomly placed, unrelated word (e.g. apple, zebra, broccoli, and banana)</strong> within the MDMT (Multi-Dimensional Measure of Trust) scale. Participants were expected to select “Does Not Fit” for these words, serving as an attention check.</p>

                    <br>
                    <h4>Participants</h4>
                    <div class="row">
                        <div class="col-md-6">
                            <p>Sample size was determined via simulation power analysis, assuming:</p>
                            <img src="img/project-img/hri-power.png" alt="" class="img-responsive" style="width: 45%; height: auto;  margin: 0; display: block;">
                        </div>
                        <div class="col-md-6">
                            <ul>
                                <li>Participants were recruited through Amazon Mechanical Turk.</li>
                                <li>Total of 210 participants: 105 in the no robot failures condition and 105 in the robot failures condition</li>
                                <li>Each participant had 45 minutes to complete the survey.</li>
                                <li>Age range: 20 to 69</li>
                            </ul>
                        </div>
                        <h5>Participants' Gender Identification:</h5>
                        <img src="img/project-img/hri-participants.png" alt="" class="img-responsive" style="width: 40%; height: auto;  margin: 0; display: block;">
                    </div>

                    <h4>Data Analysis</h4>
                    <p>All analyses and visualizations were conducted in Python using packages such as pandas, statsmodels, pingouin, and seaborn.</p>

                    <h5>Data Preparation</h5>
                    <ul>
                        <li>Dataset was imported from a processed Excel file.</li>
                        <li>"None" values were replaced with missing data indicators (NA).</li>
                        <li>Several columns were cast to categorical types: including participant demographics (gender, age, and experience with robots), experimental conditions (type: failures/no failures, context, and the gender of the user interacting with the robot), and participant IDs.</li>
                    </ul>

                    <img src="img/project-img/hri-data.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0; display: block;">


                    <h5>Metrics Calculations</h5>
                    <ul>
                        <li>First, to assess the internal consistency of the rating subscales, Cronbach’s alpha was computed for each using the pingouin package in Python. All subscales demonstrated high internal reliability, with alpha ≥ 0.81.</li>
                        <li>Next, the mean was calculated for each of the five subscales of the MDMT and RoSAS scales.</li>
                    </ul>

                    <h5>Statistical Modeling</h5>
                    <ul>
                        <li>To assess the effects of experimental manipulations and participant characteristics, <strong>linear-mixed-effect models</strong> were fitted using the statsmodels package.</li>
                        <li><strong>Participant ID</strong> was included as a <strong>random effect</strong> to account for repeated measures.</li>
                        <li>Then, various combinations of fixed effects, presented in the results, were tested to identify statistically significant difference.</li>
                    </ul>

                    <div class="divider" id="ai2">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  

                    <h3>RESULTS</h3>

                    <h4>Perceived Robot’s Gender</h4>
                    <div class="row">
                        <div class="col-md-6">
                            <h5 style="text-align: center;">Distribution of Perceived Robot’s Gender by Performace and Context</h5>
                            <img src="img/project-img/hri-gender-graph.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-6">
                            <p>Across both Failure and No Failure conditions and in both contexts, the majority of participants rated the robot’s gender as 1-Male and 2-Male/Ambiguous, indicating a perception towards male.</p>
                            <p>When the robot had No Failures, most participants assigned 2-Male/Ambiguous, 38.1% for Assistant and 40% for IT Support.</p>
                            <p>When the robot had Failures, this rate decreased by 10%, distributing the ratings in the other scales.</p>
                            <p>There is no significant difference when comparing the 2 different contexts (Assistance and IT Support). </p>
                        </div>
                    </div>

                    <h4>Comparing the No Failures and Failures Metrics Results</h4>
                    <div class="row">
                        <div class="col-md-5">
                            <h5 style="text-align: center;">Mean Scores for Failures vs No Failures</h5>
                            <img src="img/project-img/hri-f-nf.png" alt="" class="img-responsive" style="width: 70%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-7">
                            <br>
                            <p>There was a <strong>significant difference</strong> across all variables, <strong>except</strong> for the <strong>Warmth</strong> (b = 0.46, p = 0.09) metric:</p>
                            <p>When the robot presented <strong>No Failures</strong>, participants rated the <strong>Reliable</strong> (b = 2.38, p < .001), <strong>Capable</strong>  (b = 2.53, p < .001), and <strong>Ethical</strong> (b = 2.23, p < .001) metrics <strong>higher</strong>.</p>
                            <p>Contrary, in this same case, participants rated the <strong>Discomfort lower</strong> (b = -0.80, p < .001)</p>
                        </div>
                    </div>

                    <br>
                    <h4>Comparing the Assistant and IT Support Context Results</h4>
                    <div class="row">
                        <div class="col-md-5">
                            <h5 style="text-align: center;">Mean Scores for Assistant vs. IT Support</h5>
                            <img src="img/project-img/hri-a-it.png" alt="" class="img-responsive" style="width: 65%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-7">
                            <br>
                            <br>
                            <p>The Reliable (b = 0.06, p = 0.12), Capable (b = 0.08, p = 0.06), and Ethical (b = 0.02, p = 0.62) metrics showed a <strong>slightly higher</strong> rate in the <strong>IT Support</strong> context, but there is <strong>no significant difference</strong>.</p>
                            <p>On the contrary, Warmth (b = -0.05, p = 0.28) and Discomfort (b = -0.07, p = 0.10) metrics show a <strong>slightly higher</strong> rate in the <strong>Assistant</strong> context, but it is also <strong>not significant</strong>.</p>
                        </div>
                    </div>

                    <br>
                    <h4>Comparing the Effect of the User Gender (Female vs Male) Interacting with the Robot</h4>
                    <div class="row">
                        <div class="col-md-5">
                            <h5 style="text-align: center;">Mean Scores for Female vs. Male Users</h5>
                            <img src="img/project-img/hri-f-m.png" alt="" class="img-responsive" style="width: 60%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-7">
                            <br>
                            <br>
                            <p>Across all five dependent variables (Reliable, Capable, Ethical, Warmth, Discomfort), the effect of the user’s gender (male & female) interacting with the robot in the videos is <strong>not statistically significantly different</strong>.</p>
                        </div>
                    </div>

                    <br>
                    <h4>Comparing the Participant’s Experience Groups (More Experience vs Less Previous Experience with Robots)</h4>
                    <div class="row">
                        <div class="col-md-5">
                            <h5 style="text-align: center;">Mean Scores for Experience Groups</h5>
                            <img src="img/project-img/hri-le-me.png" alt="" class="img-responsive" style="width: 85%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-7">
                            <br>
                            <br>
                            <p>Participants with <strong>more previous experience with robots</strong> rated the robot <strong>significantly higher</strong> on the variables of <strong>Reliable</strong> (b = 0.89, p < .001), <strong>Capable</strong> (b = 0.81, p = 0.004), <strong>Ethical</strong> (b = 0.76, p = 0.004), and <strong>Warmth</strong> (b = 0.77, p = 0.005)</p>
                            <p>For Discomfort, participants with less prior experience gave slightly higher ratings (b = -0.09, p = 0.61), but this difference was not statistically significant.</p>
                        </div>
                    </div>

                    <br>
                    <h4>Comparing the Participant’s Age Groups (Younger-Below 32 vs Older)</h4>
                    <div class="row">
                        <div class="col-md-5">
                            <h5 style="text-align: center;">Mean Scores for Participants' Age Groups</h5>
                            <img src="img/project-img/hri-y-o.png" alt="" class="img-responsive" style="width: 60%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-7">
                            <br>
                            <br>
                            <p>In the Reliable (b = -0.40, p = 0.16), Capable (b = -0.42, p = 0.14), and Ethical (b = -0.50, p = 0.06) metrics, there are no significant differences, older participants gave a slightly higher rate.</p>
                            <p>However, in the <strong>Warmth</strong> (b = -0.95, p < .001) and <strong>Discomfort</strong> (b = -0.60, p < .001) metrics, <strong>older participants</strong> also rated these <strong>higher</strong>, and these showed a <strong>significant difference</strong>.</p>
                        </div>
                    </div>

                    
                    
                    <div class="divider" id="ai2">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  

                    <h3>DISCUSSION</h3>
                    
                    <div class="divider" id="ai2">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  
                    
                    <h3>REFLECTION</h3>


                    <h4>Future Work</h4>

                    <ul>
                        <li><strong>Deep Learning Models: </strong>Exploring deep learning models like recurrent neural networks (RNNs) or transformers could offer even better performance on sentiment classification tasks involving large text datasets.</li>
                        <li><strong>Data Sources: </strong>Look for additional data sources or more diverse datasets to train and evaluate the models, improving generalization.</li>
                    </ul>


                    <h4>Persona Takeaways</h4>

                    <ul>
                        <li>Gained insights into the strengths and weaknesses of different classification algorithms (Naïve Bayes vs. SVM) and how their performance varies based on the dataset.</li>
                        <li>Became interested in exploring more advanced techniques and algorithms for text classification, recognizing the potential for improved performance.</li>
                    </ul>



                        </div>
                    </div>
                </div>
                <!-- Modal Body End -->

            </div>
            <!-- Body Area End -->      
         
  
        <!-- Footer Area Start -->
        <div id="footer">
            <!-- Contact Social Start -->
            <div class="contact--social">
                <ul>
                    <li><a title="LinkedIn" target="_blank" href="https://www.linkedin.com/in/natalia-ra04/"><i class="fa fa-linkedin"></i></a></li>
                    <li><a title="GitHib" target="_blank" href="https://github.com/naty-rodrig99"><i class="fa fa-github"></i></a></li>                   
                </ul>
            </div>
            <!-- Contact Social End -->            
            <div class="container">
                <!-- Footer Copyright Start -->
                <div class="footer--copyright" style="font-weight: 300; color: #999999;">
                    <p>Copyright &copy; 2025 <a href="index.html" style=" color: #999999;">Natalia Rodriguez</a>. All Rights Reserved.</p>
                </div>
                <!-- Footer Copyright End -->
            </div>
        </div>
        <!-- Footer Area End -->
        
        <!-- Back To Top Area Start -->
        <div id="backToTop">
            <a href="#header" class="btn--default AnimateScrollLink"><i class="fa fa-angle-up"></i></a>
        </div>
        <!-- Back To Top Area End -->
    </div>
    <!-- Wrapper End -->

    <!-- ==== jQuery ==== -->
    <script src="js/jquery.min.js"></script>

    <!-- ==== Bootstrap ==== -->
    <script src="js/bootstrap.min.js"></script>

    <!-- ==== jQuery UI DatePicker Plugin ==== -->
    <script src="js/jquery-ui.min.js"></script>

    <!-- ==== Owl Carousel Plugin ==== -->
    <script src="js/owl.carousel.min.js"></script>

    <!-- ==== Isotope Plugin ==== -->
    <script src="js/isotope-docs.min.js"></script>
    
    <!-- ==== jQuery Form Plugin ==== -->
    <script src="js/jquery.form.min.js"></script>
    
    <!-- ==== jQuery Validation Plugin ==== -->
    <script src="js/jquery.validate.min.js"></script>

    <!-- ==== Google Map API ==== -->
    <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBK9f7sXWmqQ1E-ufRXV3VpXOn_ifKsDuc"></script>
    
    <!-- ==== GMaps Plugin ==== -->
    <script src="js/gmaps.min.js"></script>
    
    <!-- ==== jQuery Waypoints Plugin ==== -->
    <script src="js/jquery.waypoints.min.js"></script>
    
    <!-- ==== Animate Scroll Plugin ==== -->
    <script src="js/animatescroll.min.js"></script>
    
    <!-- ==== CounterUp Plugin ==== -->
    <script src="js/jquery.counterup.min.js"></script>
    
    <!-- ==== jQuery Nice Scroll Plugin ==== -->
    <script src="js/jquery.nicescroll.min.js"></script>
    
    <!-- ==== Parallax Plugin ==== -->
    <script src="js/parallax.min.js"></script>
    
    <!-- ==== jQuery Tubular Plugin ==== -->
    <script src="js/jquery.tubular.1.0.js"></script>
    
    <!-- ==== RetinaJS Plugin ==== -->
    <script src="js/retina.min.js"></script>

    <!-- ==== Main Script ==== -->
    <script src="js/main.js"></script>

</body>
</html>

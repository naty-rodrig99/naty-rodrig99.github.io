<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Natalia Rodriguez</title>
    
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    
    <meta name="description" content="">
    <meta name="author" content="">

    <!-- ====Favicons==== -->
    <!-- <link rel="shortcut icon" href="img/favicon.png" type="image/x-icon"> -->
    <link rel="icon" href="favicon.png" type="image/x-icon">
    
    <!-- ==== Google Font ==== -->
    <link href="https://fonts.googleapis.com/css?family=Lato:300,400,700" rel="stylesheet">

    <!-- ==== Font Awesome ==== -->
    <link href="css/font-awesome.min.css" rel="stylesheet">
    
    <!-- ==== Bootstrap ==== -->
    <link href="css/bootstrap.min.css" rel="stylesheet">
    
    <!-- ==== jQuery UI ==== -->
    <link href="css/jquery-ui.min.css" rel="stylesheet">
    
    <!-- ==== Owl Carousel Plugin ==== -->
    <link href="css/owl.carousel.min.css" rel="stylesheet">
    
    <!-- ====Main Stylesheet==== -->
    <link href="style.css" rel="stylesheet">
    
    <!-- ====Custom Stylesheet==== -->
    <link href="css/custom-style.css" rel="stylesheet">

    <!-- Global site tag (gtag.js) - Google Analytics -->
    <script async src="https://www.googletagmanager.com/gtag/js?id=UA-157444923-1"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());

      gtag('config', 'UA-157444923-1');
    </script>

    <style>
        #myCarousel li{
            background-color: rgba(0,0,0,.2);
            border: initial;
        }

        #myCarousel li.active{
            background-color: #666;
        }

        #myCarousel ol {
            bottom: -50px; letter-spacing: 3px; z-index: 0;
        }

    </style>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
        <script src="js/html5shiv.min.js"></script>
        <script src="js/respond.min.js"></script>
    <![endif]-->
</head>
<body data-spy="scroll" data-target=".navbar" data-offset="100">
    <!-- Wrapper Start -->
    <div class="wrapper">


        <!-- Side Nav Start -->
                        <div class="side" id="side">
                            <ul>
                                <li><a href="#hri1">Overview</a></li>
                                <li><a href="#hri2">Methodology</a></li>
                                <li><a href="#hri3">Results</a></li>
                                <li><a href="#hri4">Limitations</a></li>
                                <li><a href="#hri5">Reflection</a></li>
                            <!--<li><a href="#RM">Remarks</a></li>-->
                            </ul>
                        </div>
        <!-- Side Nav End -->
        
        <!-- Header Area Start -->
        <div id="header">
            <nav class="header--navbar">
                <div class="container">
                    <div class="navbar">
                        <div class="navbar-header">
                        
                            <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#headerNav" aria-expanded="false" aria-controls="headerNav">
                                <span class="sr-only">Toggle navigation</span>
                                <span class="icon-bar"></span>
                                <span class="icon-bar"></span>
                                <span class="icon-bar"></span>
                            </button>
                            
                            <!-- Logo Start -->
                            <a class="logo navbar-brand" href="index.html">
                                
                                <div class="logo--content" id="logo--content">
                                    <h1>Natalia Rodriguez</h1>
                                    <p>Portfolio</p>
                                </div>
                            </a>
                            <!-- Logo End -->
                        </div>
                       
                        <div id="headerNav" class="header--nav navbar-collapse collapse">
                            <ul class="nav navbar-nav navbar-right AnimateScroll">
                                <li><a href="https://naty-rodrig99.github.io//#header">HOME</a></li>
                                <li><a href="https://naty-rodrig99.github.io//#gallery">PROJECTS</a></li>
                                <li><a href="https://naty-rodrig99.github.io//#skills">SKILLS</a></li>
                                <li><a href="https://naty-rodrig99.github.io//#about">ABOUT</a></li>
                                <!--<li><a href="/pdf/peiyunchung_cv.pdf" target="_blank">RESUME</a></li> -->          
                                <li><a href="https://www.linkedin.com/in/natalia-ra04/">LINKEDIN</a></li>
                            </ul>
                        </div>
                        <!-- Header Nav End -->
                    </div>
                </div>
            </nav>
        </div>
        <!-- Header Area End -->

            <!-- Body Area Start -->
            <div class="container">

                <!-- Modal Body Start -->
                <div class="modal-body">
                    <div class="row">
                        <div class="col-md-offset-1 col-md-10 col-xs-offset-1 col-xs-10 reset-padding post-title">
                            <h2 id="ai1">Research on Trust, Gender, and Social Perception in Human-Robot Interactions</h2>
                            <h4>Master's Thesis Project</h4>
                        </div>

                        <div class="col-md-12" style="text-align: center;" id="hri1">
                            <img src="img/project-img/hri-main.png" alt="" class="img-responsive" style="width: 35%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        
                        <div class="col-md-offset-1 col-md-10 col-xs-offset-1 col-xs-10 reset-padding post-content">

                    <div class="row">
                        <div class="col-md-8">

                            <h5>OVERVIEW</h5>
                            <p>As artificial intelligence and social robots become more common in daily life, their success depends not only on technical performance but also on how humans perceive and interact with them. People naturally anthropomorphize robots, projecting traits and social expectations, especially when robots have cues like voice, facial expressions, or body language. These design choices, particularly related to gender, influence perceptions of trust, competence, and role suitability. Feminist robot studies have highlighted how gendered designs can reinforce harmful stereotypes, promoting calls for more inclusive and ethically responsible design approaches. </p>


                            <h5>OBJECTIVE</h5>
                            <p>While previous research has focused on male and female robot personas, little is known about how users respond to gender-ambiguous robots. This study explores how trust and perception are shaped by a gender-ambiguous robot's performance and task context, considering user characteristics like age and previous experience with robots. By doing so, it challenges traditional gender norms in robot design and advocates for more socially aware and inclusive human-robot interaction practices.</p>
                            
                            <h5>PROBLEM STATEMENT</h5>
                            <p style="text-align: center"><strong>"How do user interactions with a gender-ambiguous social robot vary with task performance and task context?"</strong></p>

                        </div>

                        <div class="col-md-1"></div>                     
                          
                        <div class="col-md-3">
                            <h5>ITEM</h5>
                            <p>Master's Thesis Project</p> 

                            <h5>METHODS</h5>
                            <p>Survey, Quantitative Research, Statistical Analysis</p>

                            <h5>TOOLS</h5>
                            <p>Furhat Robot, Python, Amazon Mechanical Turk, Kotlin</p>  
                            
                            <h5>PRESENTATION</h5>
                            <u><a href="https://docs.google.com/presentation/d/1TgqQyYk-CzLJFn9yWHA7Bpok_JaUIK8wFPDs-Xs1wq0/edit?usp=sharing">Slides</a></u>

                            <h5>TEAM</h5>
                            <p>Individual</p>
                            
                            <h5>PERIOD</h5>
                            <p>February 2025 - August 2025</p> 
                        </div>
                    </div>

                    <h4>Hypotheses</h4>
                    <p>To structure the study, these hypotheses have been defined. These reflect the expectations about how failures, task context, and participant differences affect trust, gender perception, and social perception of the robot:</p>
                    <img src="img/project-img/hri-hypotheses.png" alt="" class="img-responsive" style="width: 50%; height: auto; margin: 0 auto; display: block;">
                    
                    <div class="divider" id="hri2">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  

                    <h3>METHODOLOGY</h3>
                    <p>The experiment involves defining two different contexts that have been determined to be stereotypically more associated with a role that a male would perform, and another role that is more associated with a task a female would do. Then, recording videos of different users interacting with the robot, in half of the videos the robot will perform without failures, and in the other half with failures. Followed by creating a survey and recruiting participants to watch and rate the different interactions. Lastly, a statistical analysis will be performed to come up with conclusions.</p>

                    <br>

                    <h4>Experiment Design</h4>

                    <div class="row">
                        <div class="col-md-7">
                            <h5>Robot Selection</h5>
                            <p><bold>Furhat robot</bold> was chosen for this experiment, since it allows to <bold>customize</bold> the <bold>face and voice</bold>, enabling the creation of an <bold>intentionally ambiguous</bold> appearance, as well as its established use in prior social robotics research.</p>  
                            <ul>
                                <li>Face: Ted</li>
                                <li>Voice: Amazon Polly’s “Kendra” voice with a lowered pitch</li>
                            </ul>
                        </div>
                        
                        <div class="col-md-5">
                            <img src="img/project-img/hri-furhat.jpeg" alt="" class="img-responsive" style="width: 30%; height: auto;  margin: 0; display: block;">
                        </div>
                    </div>

                    <br>

                    <div class="row">
                        <div class="col-md-6">
                            <img src="img/project-img/hri-contexts.png" alt="" class="img-responsive" style="width: 60%; height: auto; margin-left: auto; margin-right: auto; display: block;">
                        </div>
                        
                        <div class="col-md-6">
                            <h5>Context Design</h5>
                            <p>To examine how task stereotypes influence perceptions of a gender-ambiguous robot, two contexts were selected based on common gender associations in past research:</p>  
                            <ul>
                                <li>Assistant: perceived as a female task, due to its frequent use in voice assistant design and associations with caregiving and support.</li>

                                <li>IT Support: perceived as a male task, due to its commonly societal associations with technology and robots.</li>
                            </ul>
                        </div>  
                    </div>

                    <br>

                    <div class="row">
                        <div class="col-md-6">
                            <h5>Robot Behavior & Video Setup</h5>
                            <p>For each context, Furhat was programmed to behave in 2 ways:</p>  
                            <ul>
                                <li>Robot functioning with <strong>technical</strong> (speaking slowly and crashing) and <strong>interaction</strong> (providing the user nonsensical responses) <bold>failures</bold>.</li>
                                <li>Robot functioning <strong>without any failures</strong> while responding to the user.</li>
                            </ul>
                        </div>
                        
                        <div class="col-md-6">
                            <h5>Video Example</h5>
                            <iframe width="360" height="215" src="https://www.youtube.com/embed/jYem_HGhyrI?si=SPeOk3yCFpwpC3Ox" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen></iframe>
                        </div>
                    </div>

                    <br>

                    <h4>Survey Design</h4>
                    <ul>
                        <li>A survey was used to enable statistical analysis, apply validated scales (e.g., trust, social perception), and ensure comparability with prior HRI studies.</li>
                        <li>Built on Amazon Mechanical Turk with custom HTML/CSS, participants were randomly shown either 4 failure or 4 no-failure videos. </li>
                        <li>After giving consent and sharing demographics, participants rated trust, social perception, and the robot’s perceived gender after each video.</li>
                    </ul>
                    
                    <img src="img/project-img/hri-methodology.png" alt="" class="img-responsive" style="width: 90%; height: auto;  margin: 0 auto; display: block;">

                    <h4>Metrics</h4>
                    <p>The following metrics were used to measure trust, social perception, and the robot’s perceived gender. Each used a Likert scale, and the items within each scale were randomized to reduce order effects.</p>

                    <div class="row">
                        <div class="col-md-4">
                            <img src="img/project-img/hri-mdmt.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0; display: block;">
                        </div>                        
                        <div class="col-md-4">
                            <img src="img/project-img/hri-rosas.png" alt="" class="img-responsive" style="width: 80%; height: auto;  margin: 0; display: block;">
                        </div>
                        <div class="col-md-4">
                            <img src="img/project-img/hri-gender.png" alt="" class="img-responsive" style="width: 90%; height: auto;  margin: 0; display: block;">
                        </div>
                    </div>

                    <h4>Attention Checks</h4>
                    <p>To ensure participant attention, an open-ended question was included among the trait items <strong>asking participants to describe what the robot in the video is doing</strong>. Additionally, each video rating included a <strong>randomly placed, unrelated word (e.g. apple, zebra, broccoli, and banana)</strong> within the MDMT (Multi-Dimensional Measure of Trust) scale. Participants were expected to select “Does Not Fit” for these words, serving as an attention check.</p>

                    <br>
                    <h4>Participants</h4>
                    <p>The sample size was calculated using simulation power analysis, assuming a moderate effect size (Cohen’s d = 0.5), the study design with 210 participants and 4 repeated measures (4 videos) per participant achieves approximately 91% power to detect condition effects at α = 0.05. </p>
                    <ul>
                        <li>Participants were recruited through Amazon Mechanical Turk.</li>
                        <li>Total of 210 participants: 105 in the no robot failures condition and 105 in the robot failures condition</li>
                        <li>Each participant had 45 minutes to complete the survey.</li>
                        <li>Age range: 20 to 69</li>
                    </ul>
                    <h5>Participants' Gender Identification:</h5>
                    <img src="img/project-img/hri-participants.png" alt="" class="img-responsive" style="width: 40%; height: auto;  margin: 0; display: block;">

                    <h4>Data Analysis</h4>
                    <p>All analyses and visualizations were conducted in Python using packages such as pandas, statsmodels, pingouin, and seaborn.</p>

                    <h5>Data Preparation</h5>
                    <ul>
                        <li>Dataset was imported from a processed Excel file.</li>
                        <li>"None" values were replaced with missing data indicators (NA).</li>
                        <li>Several columns were cast to categorical types: including participant demographics (gender, age, and experience with robots), experimental conditions (type: failures/no failures, context, and the gender of the user interacting with the robot), and participant IDs.</li>
                    </ul>

                    <img src="img/project-img/hri-data.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0; display: block;">


                    <h5>Metrics Calculations</h5>
                    <ul>
                        <li>First, to assess the internal consistency of the rating subscales, Cronbach’s alpha was computed for each using the pingouin package in Python. All subscales demonstrated high internal reliability, with alpha ≥ 0.81.</li>
                        <li>Next, the mean was calculated for each of the five subscales of the MDMT and RoSAS scales.</li>
                    </ul>

                    <h5>Statistical Modeling</h5>
                    <ul>
                        <li>To assess the effects of experimental manipulations and participant characteristics, <strong>linear-mixed-effect models</strong> were fitted using the statsmodels package.</li>
                        <li><strong>Participant ID</strong> was included as a <strong>random effect</strong> to account for repeated measures.</li>
                        <li>Then, various combinations of fixed effects, presented in the results, were tested to identify statistically significant difference.</li>
                    </ul>

                    <div class="divider" id="hri3">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  

                    <h3>RESULTS</h3>

                    <h4 style="text-align: center;">Results Summary</h4>
                    <img src="img/project-img/hri-results-summary.png" alt="" class="img-responsive" style="width: 60%; height: auto;  margin: 0 auto; display: block;">

                    <h4><strong>H1:</strong> Trust and social perception will decrease when the robot has failures</h4>
                    <div class="row">
                        <div class="col-md-5">
                            <h5 style="text-align: center;">Mean Scores for Failures vs No Failures</h5>
                            <img src="img/project-img/hri-f-nf.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-7">
                            <br>
                            <br>
                            <ul>
                                <li><strong>Trust:</strong> Significant difference in all variables.</li>
                                <li><strong>Social perception:</strong> Significant difference in discomfort, not in warmth.</li>
                            </ul>
                        </div>
                    </div>

                    <h4><strong>H2:</strong> Trust and social perception will vary depending on the robot’s task context</h4>
                    <div class="row">
                        <div class="col-md-5">
                            <h5 style="text-align: center;">Mean Scores by Type and Context</h5>
                            <img src="img/project-img/hri-t-c.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-7">
                            <br>
                            <ul>
                                <li><strong>No significant difference</strong> - Assistant vs IT Support.</li>
                                <li><strong>Assistant</strong> context had <strong>stronger drop trust</strong> when the robot had failures.</li>
                                <ul>
                                    <li>Suggest gender-role biases in how trust is affected.</li>
                                </ul>
                            </ul>
                        </div>
                    </div>
                    
                    <br>
                    <h4><strong>H3:</strong> Participants will perceive the robot’s gender based on stereotypical associations with the task context</h4>
                    <div class="row">
                        <div class="col-md-6">
                            <h5 style="text-align: center;">Distribution of Perceived Robot’s Gender by Performace and Context</h5>
                            <img src="img/project-img/hri-gender-graph.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-6">
                            <br>
                            <br>
                            <ul>
                                <li>Robot was <strong>perceived as male</strong> across contexts.</li>
                                <li><strong>Slight ambiguity</strong> when the robot had <strong>failures</strong>.</li>
                                <li>Reflected the ”male-by-default” trend.</li>
                            </ul>
                        </div>
                    </div>
                    

                    <h4><strong>H4:</strong> Participant age and prior experience with robots will influence trust and social perception</h4>
                    <div class="row">
                        <div class="col-md-5">
                            <h5 style="text-align: center;">Pior Experience with Robots</h5>
                            <img src="img/project-img/hri-exp.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-7">
                            <br>
                            <br>
                            <br>
                            <ul>
                                <li>Participants with <strong>prior experience</strong> showed <strong>higher</strong> levels of <strong>trust</strong>.</li>
                            </ul>
                        </div>
                    </div>

                    <div class="row">
                        <div class="col-md-5">
                            <h5 style="text-align: center;">Participant's Age</h5>
                            <img src="img/project-img/hri-age.png" alt="" class="img-responsive" style="width: 100%; height: auto;  margin: 0 auto; display: block;">
                        </div>
                        <div class="col-md-7">
                            <br>
                            <br>
                            <br>
                            <ul>
                                <li>The group of <strong>older participants (>32)</strong> showed <strong>higher</strong> rates in <strong>social perception</strong>.</li>
                            </ul>
                        </div>
                    </div>

                    <div class="divider" id="hri5">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  


                    <h3>CONCLUSIONS</h3>

                    <img src="img/project-img/hri-conclusions.png" alt="" class="img-responsive" style="width: 85%; height: auto;  margin: 0 auto; display: block;">

                            
                    <div class="divider" id="hri4">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  

                    <h3>LIMITATIONS AND FUTURE WORK</h3>

                    <img src="img/project-img/hri-limitations.png" alt="" class="img-responsive" style="width: 85%; height: auto;  margin: 0 auto; display: block;">

                    
                    <div class="divider" id="hri5">
                        <div class="dot1"></div>
                        <div class="dot2"></div>
                        <div class="dot3"></div>
                    </div>  
                    
                    <h3>REFLECTION</h3>

                    <h4>Persona Takeaways</h4>
                    <ul>
                        <li>I learned the importance of carefully designing experimental conditions and hypotheses to capture complex user attitudes toward emerging technologies, such as AI and robots.</li>
                        <li>The main challenge was selecting a voice and face that were truly gender-ambiguous, as this is a relatively new and underexplored topic.</li>
                        <li>Exploring the impact of gender ambiguity in robots expanded my understanding of social biases and stereotypes in technology design, which deepened my empathy and critical thinking as a UX researcher.</li>
                        <li>Overall, this project reinforced my passion for combining technical research with human-centered design, and it motivated me to further explore how AI and robotics can be developed responsibly to promote positive user experiences.</li>
                    </ul>
                        </div>
                    </div>
                </div>
                <!-- Modal Body End -->

            </div>
            <!-- Body Area End -->      
         
  
        <!-- Footer Area Start -->
        <div id="footer">
            <!-- Contact Social Start -->
            <div class="contact--social">
                <ul>
                    <li><a title="LinkedIn" target="_blank" href="https://www.linkedin.com/in/natalia-ra04/"><i class="fa fa-linkedin"></i></a></li>
                    <li><a title="GitHib" target="_blank" href="https://github.com/naty-rodrig99"><i class="fa fa-github"></i></a></li>                   
                </ul>
            </div>
            <!-- Contact Social End -->            
            <div class="container">
                <!-- Footer Copyright Start -->
                <div class="footer--copyright" style="font-weight: 300; color: #999999;">
                    <p>Copyright &copy; 2025 <a href="index.html" style=" color: #999999;">Natalia Rodriguez</a>. All Rights Reserved.</p>
                </div>
                <!-- Footer Copyright End -->
            </div>
        </div>
        <!-- Footer Area End -->
        
        <!-- Back To Top Area Start -->
        <div id="backToTop">
            <a href="#header" class="btn--default AnimateScrollLink"><i class="fa fa-angle-up"></i></a>
        </div>
        <!-- Back To Top Area End -->
    </div>
    <!-- Wrapper End -->

    <!-- ==== jQuery ==== -->
    <script src="js/jquery.min.js"></script>

    <!-- ==== Bootstrap ==== -->
    <script src="js/bootstrap.min.js"></script>

    <!-- ==== jQuery UI DatePicker Plugin ==== -->
    <script src="js/jquery-ui.min.js"></script>

    <!-- ==== Owl Carousel Plugin ==== -->
    <script src="js/owl.carousel.min.js"></script>

    <!-- ==== Isotope Plugin ==== -->
    <script src="js/isotope-docs.min.js"></script>
    
    <!-- ==== jQuery Form Plugin ==== -->
    <script src="js/jquery.form.min.js"></script>
    
    <!-- ==== jQuery Validation Plugin ==== -->
    <script src="js/jquery.validate.min.js"></script>

    <!-- ==== Google Map API ==== -->
    <script src="https://maps.googleapis.com/maps/api/js?key=AIzaSyBK9f7sXWmqQ1E-ufRXV3VpXOn_ifKsDuc"></script>
    
    <!-- ==== GMaps Plugin ==== -->
    <script src="js/gmaps.min.js"></script>
    
    <!-- ==== jQuery Waypoints Plugin ==== -->
    <script src="js/jquery.waypoints.min.js"></script>
    
    <!-- ==== Animate Scroll Plugin ==== -->
    <script src="js/animatescroll.min.js"></script>
    
    <!-- ==== CounterUp Plugin ==== -->
    <script src="js/jquery.counterup.min.js"></script>
    
    <!-- ==== jQuery Nice Scroll Plugin ==== -->
    <script src="js/jquery.nicescroll.min.js"></script>
    
    <!-- ==== Parallax Plugin ==== -->
    <script src="js/parallax.min.js"></script>
    
    <!-- ==== jQuery Tubular Plugin ==== -->
    <script src="js/jquery.tubular.1.0.js"></script>
    
    <!-- ==== RetinaJS Plugin ==== -->
    <script src="js/retina.min.js"></script>

    <!-- ==== Main Script ==== -->
    <script src="js/main.js"></script>

</body>
</html>
